<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.0">
<title>pipelines.rj_smtr.utils API documentation</title>
<meta name="description" content="General purpose functions for rj_smtr">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pipelines.rj_smtr.utils</code></h1>
</header>
<section id="section-intro">
<p>General purpose functions for rj_smtr</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pipelines.rj_smtr.utils.bq_project"><code class="name flex">
<span>def <span class="ident">bq_project</span></span>(<span>kind:Â strÂ =Â 'bigquery_prod')</span>
</code></dt>
<dd>
<div class="desc"><p>Get the set BigQuery project_id</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>kind</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Which client to get the project name from.</dd>
</dl>
<p>Options are 'bigquery_staging', 'bigquery_prod' and 'storage_staging'
Defaults to 'bigquery_prod'.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>the requested project_id</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.check_not_null"><code class="name flex">
<span>def <span class="ident">check_not_null</span></span>(<span>data:Â pandas.core.frame.DataFrame, columns:Â list, subset_query:Â strÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if there are null values in columns.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>columns</code></strong> :&ensp;<code>list</code></dt>
<dd>list of columns to check</dd>
<dt><strong><code>subset_query</code></strong> :&ensp;<code>str</code></dt>
<dd>query to check if there are important data</dd>
</dl>
<p>being removed</p>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="pipelines.rj_smtr.utils.check_relation"><code class="name flex">
<span>def <span class="ident">check_relation</span></span>(<span>data:Â pandas.core.frame.DataFrame, columns:Â list)</span>
</code></dt>
<dd>
<div class="desc"><p>Check relation between collumns.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>dataframe to be modified</dd>
<dt><strong><code>columns</code></strong> :&ensp;<code>list</code></dt>
<dd>list of lists of columns to be checked</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="pipelines.rj_smtr.utils.close_db_connection"><code class="name flex">
<span>def <span class="ident">close_db_connection</span></span>(<span>connection, engine:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>Safely close a database connection</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>connection</code></strong></dt>
<dd>the database connection</dd>
<dt><strong><code>engine</code></strong> :&ensp;<code>str</code></dt>
<dd>The datase management system</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.connect_ftp"><code class="name flex">
<span>def <span class="ident">connect_ftp</span></span>(<span>secret_path:Â strÂ =Â None, secure:Â boolÂ =Â True)</span>
</code></dt>
<dd>
<div class="desc"><p>Connect to FTP</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ImplicitFTP_TLS</code></dt>
<dd>ftp client</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.create_bq_external_table"><code class="name flex">
<span>def <span class="ident">create_bq_external_table</span></span>(<span>table_obj:Â basedosdados.upload.table.Table, path:Â str, bucket_name:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates an BigQuery External table based on sample data</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>table_obj</code></strong> :&ensp;<code>Table</code></dt>
<dd>BD Table object</dd>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>Table data local path</dd>
<dt><strong><code>bucket_name</code></strong> :&ensp;<code>str, Optional</code></dt>
<dd>The bucket name where the data is located</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.create_bq_table_schema"><code class="name flex">
<span>def <span class="ident">create_bq_table_schema</span></span>(<span>data_sample_path:Â Union[str,Â pathlib.Path]) â€‘>Â list[google.cloud.bigquery.schema.SchemaField]</span>
</code></dt>
<dd>
<div class="desc"><p>Create the bq schema based on the structure of data_sample_path.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_sample_path</code></strong> :&ensp;<code>str, Path</code></dt>
<dd>Data sample path to auto complete columns names</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list[bigquery.SchemaField]</code></dt>
<dd>The table schema</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.create_or_append_table"><code class="name flex">
<span>def <span class="ident">create_or_append_table</span></span>(<span>dataset_id:Â str, table_id:Â str, path:Â str, partitions:Â strÂ =Â None, bucket_name:Â strÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Conditionally create table or append data to its relative GCS folder.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>target dataset_id on BigQuery</dd>
<dt><strong><code>table_id</code></strong> :&ensp;<code>str</code></dt>
<dd>target table_id on BigQuery</dd>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to .csv data file</dd>
<dt><strong><code>partitions</code></strong> :&ensp;<code>str</code></dt>
<dd>partition string.</dd>
<dt><strong><code>bucket_name</code></strong> :&ensp;<code>str, Optional</code></dt>
<dd>The bucket name to save the data.</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.custom_serialization"><code class="name flex">
<span>def <span class="ident">custom_serialization</span></span>(<span>obj:Â Any) â€‘>Â Any</span>
</code></dt>
<dd>
<div class="desc"><p>Function to serialize not JSON serializable objects</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>obj</code></strong> :&ensp;<code>Any</code></dt>
<dd>Object to serialize</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Any</code></dt>
<dd>Serialized object</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.data_info_str"><code class="name flex">
<span>def <span class="ident">data_info_str</span></span>(<span>data:Â pandas.core.frame.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"><p>Return dataframe info as a str to log</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>dataframe</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>data.info() as a string</p></div>
</dd>
<dt id="pipelines.rj_smtr.utils.dict_contains_keys"><code class="name flex">
<span>def <span class="ident">dict_contains_keys</span></span>(<span>input_dict:Â dict, keys:Â list[str]) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>Test if the input dict has all keys present in the list</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>the dict to test if has the keys</dd>
<dt><strong><code>keys</code></strong> :&ensp;<code>list[str]</code></dt>
<dd>the list containing the keys to check</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if the input_dict has all the keys otherwise False</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.execute_db_query"><code class="name flex">
<span>def <span class="ident">execute_db_query</span></span>(<span>engine:Â str, query:Â str, connection, connector, connection_info:Â dict) â€‘>Â list[dict]</span>
</code></dt>
<dd>
<div class="desc"><p>Execute a query if retries</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>query</code></strong> :&ensp;<code>str</code></dt>
<dd>the SQL Query to execute</dd>
<dt><strong><code>engine</code></strong> :&ensp;<code>str</code></dt>
<dd>The database management system</dd>
<dt><strong><code>connection</code></strong></dt>
<dd>The database connection</dd>
<dt><strong><code>connector</code></strong></dt>
<dd>The database connector (to do reconnections)</dd>
<dt><strong><code>connection_info</code></strong> :&ensp;<code>dict</code></dt>
<dd>The database connector params (to do reconnections)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list[dict]</code></dt>
<dd>The query results</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.filter_data"><code class="name flex">
<span>def <span class="ident">filter_data</span></span>(<span>data:Â pandas.core.frame.DataFrame, filters:Â list, subset_query:Â strÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Filter data from a dataframe</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>data DataFrame</dd>
<dt><strong><code>filters</code></strong> :&ensp;<code>list</code></dt>
<dd>list of queries to filter data</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>data without filter data</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.filter_null"><code class="name flex">
<span>def <span class="ident">filter_null</span></span>(<span>data:Â pandas.core.frame.DataFrame, columns:Â list, subset_query:Â strÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Filter null values in columns.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>columns</code></strong> :&ensp;<code>list</code></dt>
<dd>list of columns to check</dd>
<dt><strong><code>subset_query</code></strong> :&ensp;<code>str</code></dt>
<dd>query to check if there are important data</dd>
</dl>
<p>being removed</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>data without null values</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.format_send_discord_message"><code class="name flex">
<span>def <span class="ident">format_send_discord_message</span></span>(<span>formatted_messages:Â list, webhook_url:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>Format and send a message to discord</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>formatted_messages</code></strong> :&ensp;<code>list</code></dt>
<dd>The formatted messages</dd>
<dt><strong><code>webhook_url</code></strong> :&ensp;<code>str</code></dt>
<dd>The webhook url</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="pipelines.rj_smtr.utils.generate_df_and_save"><code class="name flex">
<span>def <span class="ident">generate_df_and_save</span></span>(<span>data:Â dict, fname:Â pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Save DataFrame as csv</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code></dt>
<dd>dict with the data which to build the DataFrame</dd>
<dt><strong><code>fname</code></strong> :&ensp;<code>Path</code></dt>
<dd><em>description</em></dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.generate_execute_schedules"><code class="name flex">
<span>def <span class="ident">generate_execute_schedules</span></span>(<span>clock_interval:Â datetime.timedelta, labels:Â List[str], table_parameters:Â Union[list[dict],Â dict], runs_interval_minutes:Â intÂ =Â 15, start_date:Â datetime.datetimeÂ =Â datetime.datetime(2020, 1, 1, 0, 0, tzinfo=&lt;DstTzInfo &#x27;America/Sao_Paulo&#x27; LMT-1 day, 20:54:00 STD&gt;), **general_flow_params) â€‘>Â List[prefect.schedules.clocks.IntervalClock]</span>
</code></dt>
<dd>
<div class="desc"><p>Generates multiple schedules</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>clock_interval</code></strong> :&ensp;<code>timedelta</code></dt>
<dd>The interval to run the schedule</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>The labels to be added to the schedule</dd>
<dt><strong><code>table_parameters</code></strong> :&ensp;<code>list</code></dt>
<dd>The table parameters to iterate over</dd>
<dt><strong><code>runs_interval_minutes</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The interval between each schedule. Defaults to 15.</dd>
<dt><strong><code>start_date</code></strong> :&ensp;<code>datetime</code>, optional</dt>
<dd>The start date of the schedule.
Defaults to datetime(2020, 1, 1, tzinfo=pytz.timezone(emd_constants.DEFAULT_TIMEZONE.value)).</dd>
<dt><strong><code>general_flow_params</code></strong></dt>
<dd>Any param that you want to pass to the flow</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[IntervalClock]</code></dt>
<dd>The list of schedules</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.get_datetime_range"><code class="name flex">
<span>def <span class="ident">get_datetime_range</span></span>(<span>timestamp:Â datetime.datetime, interval:Â datetime.timedelta) â€‘>Â dict</span>
</code></dt>
<dd>
<div class="desc"><p>Task to get datetime range in UTC</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>timestamp</code></strong> :&ensp;<code>datetime</code></dt>
<dd>timestamp to get datetime range</dd>
<dt><strong><code>interval</code></strong> :&ensp;<code>timedelta</code></dt>
<dd>interval to get datetime range</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>datetime range</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.get_last_run_timestamp"><code class="name flex">
<span>def <span class="ident">get_last_run_timestamp</span></span>(<span>dataset_id:Â str, table_id:Â str, mode:Â strÂ =Â 'prod') â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Query redis to retrive the time for when the last materialization
ran.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>dataset_id on BigQuery</dd>
<dt><strong><code>table_id</code></strong> :&ensp;<code>str</code></dt>
<dd>model filename on the queries repo.</dd>
<dt><strong><code>eg</code></strong></dt>
<dd>if you have a model defined in the file <filename>.sql,</dd>
</dl>
<p>the table_id should be <filename>
mode (str):</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[str, None]</code></dt>
<dd><em>description</em></dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.get_raw_data_api"><code class="name flex">
<span>def <span class="ident">get_raw_data_api</span></span>(<span>url:Â str, secret_path:Â strÂ =Â None, api_params:Â dictÂ =Â None, filetype:Â strÂ =Â None) â€‘>Â tuple[str,Â str,Â str]</span>
</code></dt>
<dd>
<div class="desc"><p>Request data from URL API</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>URL to request data</dd>
<dt><strong><code>secret_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Secret path to get headers. Defaults to None.</dd>
<dt><strong><code>api_params</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Parameters to pass to API. Defaults to None.</dd>
<dt><strong><code>filetype</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Filetype to save raw file. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple[str, str, str]</code></dt>
<dd>Error, data and filetype</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.get_raw_data_db"><code class="name flex">
<span>def <span class="ident">get_raw_data_db</span></span>(<span>query:Â str, engine:Â str, host:Â str, secret_path:Â str, database:Â str, page_size:Â intÂ =Â None, max_pages:Â intÂ =Â None) â€‘>Â tuple[str,Â str,Â str]</span>
</code></dt>
<dd>
<div class="desc"><p>Get data from Databases</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>query</code></strong> :&ensp;<code>str</code></dt>
<dd>the SQL Query to execute</dd>
<dt><strong><code>engine</code></strong> :&ensp;<code>str</code></dt>
<dd>The database management system</dd>
<dt><strong><code>host</code></strong> :&ensp;<code>str</code></dt>
<dd>The database host</dd>
<dt><strong><code>secret_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Secret path to get credentials</dd>
<dt><strong><code>database</code></strong> :&ensp;<code>str</code></dt>
<dd>The database to connect</dd>
<dt><strong><code>page_size</code></strong> :&ensp;<code>int, Optional</code></dt>
<dd>The maximum number of rows returned by the paginated query
if you set a value for this argument, the query will have LIMIT and OFFSET appended to it</dd>
<dt><strong><code>max_pages</code></strong> :&ensp;<code>int, Optional</code></dt>
<dd>The maximum number of paginated queries to execute</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple[str, str, str]</code></dt>
<dd>Error, data and filetype</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.get_raw_data_gcs"><code class="name flex">
<span>def <span class="ident">get_raw_data_gcs</span></span>(<span>dataset_id:Â str, table_id:Â str, zip_filename:Â strÂ =Â None, bucket_name:Â strÂ =Â None) â€‘>Â tuple[str,Â str,Â str]</span>
</code></dt>
<dd>
<div class="desc"><p>Get raw data from GCS</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The dataset id on BigQuery.</dd>
<dt><strong><code>table_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The table id on BigQuery.</dd>
<dt><strong><code>zip_filename</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The zip file name. Defaults to None.</dd>
<dt><strong><code>bucket_name</code></strong> :&ensp;<code>str, Optional</code></dt>
<dd>The bucket name to get the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple[str, str, str]</code></dt>
<dd>Error, data and filetype</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.get_raw_recursos"><code class="name flex">
<span>def <span class="ident">get_raw_recursos</span></span>(<span>request_url:Â str, request_params:Â dict) â€‘>Â tuple[str,Â str,Â str]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a dataframe with recursos data from movidesk api.</p></div>
</dd>
<dt id="pipelines.rj_smtr.utils.get_table_min_max_value"><code class="name flex">
<span>def <span class="ident">get_table_min_max_value</span></span>(<span>query_project_id:Â str, dataset_id:Â str, table_id:Â str, field_name:Â str, kind:Â str, wait=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Query a table to get the maximum value for the chosen field.
Useful to incrementally materialize tables via DBT</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>dataset_id on BigQuery</dd>
<dt><strong><code>table_id</code></strong> :&ensp;<code>str</code></dt>
<dd>table_id on BigQuery</dd>
<dt><strong><code>field_name</code></strong> :&ensp;<code>str</code></dt>
<dd>column name to query</dd>
<dt><strong><code>kind</code></strong> :&ensp;<code>str</code></dt>
<dd>which value to get. Accepts min and max</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.get_upload_storage_blob"><code class="name flex">
<span>def <span class="ident">get_upload_storage_blob</span></span>(<span>dataset_id:Â str, filename:Â str, bucket_name:Â strÂ =Â None) â€‘>Â google.cloud.storage.blob.Blob</span>
</code></dt>
<dd>
<div class="desc"><p>Get a blob from upload zone in storage</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The dataset id on BigQuery.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>The filename in GCS.</dd>
<dt><strong><code>bucket_name</code></strong> :&ensp;<code>str, Optional</code></dt>
<dd>The bucket name to get the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Blob</code></dt>
<dd>blob object</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.log_critical"><code class="name flex">
<span>def <span class="ident">log_critical</span></span>(<span>message:Â str, secret_path:Â strÂ =Â 'critical_webhook')</span>
</code></dt>
<dd>
<div class="desc"><p>Logs message to critical discord channel specified</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>message</code></strong> :&ensp;<code>str</code></dt>
<dd>Message to post on the channel</dd>
<dt><strong><code>secret_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Secret path storing the webhook to critical channel.</dd>
</dl>
<p>Defaults to constants.CRITICAL_SECRETPATH.value.</p></div>
</dd>
<dt id="pipelines.rj_smtr.utils.map_dict_keys"><code class="name flex">
<span>def <span class="ident">map_dict_keys</span></span>(<span>data:Â dict, mapping:Â dict) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Map old keys to new keys in a dict.</p></div>
</dd>
<dt id="pipelines.rj_smtr.utils.perform_check"><code class="name flex">
<span>def <span class="ident">perform_check</span></span>(<span>desc:Â str, check_params:Â dict, request_params:Â dict) â€‘>Â dict</span>
</code></dt>
<dd>
<div class="desc"><p>Perform a check on a query</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>desc</code></strong> :&ensp;<code>str</code></dt>
<dd>The check description</dd>
<dt><strong><code>check_params</code></strong> :&ensp;<code>dict</code></dt>
<dd>The check parameters
* query (str): SQL query to be executed
* order_columns (list): order columns for query log results, in case of failure (optional)</dd>
<dt><strong><code>request_params</code></strong> :&ensp;<code>dict</code></dt>
<dd>The request parameters</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>The check status</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.perform_checks_for_table"><code class="name flex">
<span>def <span class="ident">perform_checks_for_table</span></span>(<span>table_id:Â str, request_params:Â dict, test_check_list:Â dict, check_params:Â dict) â€‘>Â dict</span>
</code></dt>
<dd>
<div class="desc"><p>Perform checks for a table</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>table_id</code></strong> :&ensp;<code>str</code></dt>
<dd>The table id</dd>
<dt><strong><code>request_params</code></strong> :&ensp;<code>dict</code></dt>
<dd>The request parameters</dd>
<dt><strong><code>test_check_list</code></strong> :&ensp;<code>dict</code></dt>
<dd>The test check list</dd>
<dt><strong><code>check_params</code></strong> :&ensp;<code>dict</code></dt>
<dd>The check parameters</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>The checks</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.read_raw_data"><code class="name flex">
<span>def <span class="ident">read_raw_data</span></span>(<span>filepath:Â str, reader_args:Â dictÂ =Â None) â€‘>Â tuple[str,Â pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Read raw data from file</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>filepath to read</dd>
<dt><strong><code>reader_args</code></strong> :&ensp;<code>dict</code></dt>
<dd>arguments to pass to pandas.read_csv or read_json</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple[str, pd.DataFrame]</code></dt>
<dd>error and data</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.safe_cast"><code class="name flex">
<span>def <span class="ident">safe_cast</span></span>(<span>val, to_type, default=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Safe cast value.</p></div>
</dd>
<dt id="pipelines.rj_smtr.utils.save_raw_local_func"><code class="name flex">
<span>def <span class="ident">save_raw_local_func</span></span>(<span>data:Â Union[dict,Â str], filepath:Â str, mode:Â strÂ =Â 'raw', filetype:Â strÂ =Â 'json') â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Saves json response from API to .json file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Union[dict, str]</code></dt>
<dd>Raw data to save</dd>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path which to save raw file</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Folder to save locally, later folder which to upload to GCS.</dd>
<dt><strong><code>filetype</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The file format</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Path to the saved file</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.save_treated_local_func"><code class="name flex">
<span>def <span class="ident">save_treated_local_func</span></span>(<span>filepath:Â str, data:Â pandas.core.frame.DataFrame, error:Â str, mode:Â strÂ =Â 'staging') â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Save treated file to CSV.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to save file</dd>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Dataframe to save</dd>
<dt><strong><code>error</code></strong> :&ensp;<code>str</code></dt>
<dd>Error catched during execution</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Folder to save locally, later folder which to upload to GCS.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Path to the saved file</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.set_redis_rdo_files"><code class="name flex">
<span>def <span class="ident">set_redis_rdo_files</span></span>(<span>redis_client, dataset_id:Â str, table_id:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>Register downloaded files to Redis</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>redis_client</code></strong> :&ensp;<code>_type_</code></dt>
<dd><em>description</em></dd>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>dataset_id on BigQuery</dd>
<dt><strong><code>table_id</code></strong> :&ensp;<code>str</code></dt>
<dd>table_id on BigQuery</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>if the key was properly set</dd>
</dl></div>
</dd>
<dt id="pipelines.rj_smtr.utils.upload_run_logs_to_bq"><code class="name flex">
<span>def <span class="ident">upload_run_logs_to_bq</span></span>(<span>dataset_id:Â str, parent_table_id:Â str, timestamp:Â str, error:Â strÂ =Â None, previous_error:Â strÂ =Â None, recapture:Â boolÂ =Â False, mode:Â strÂ =Â 'raw', bucket_name:Â strÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Upload execution status table to BigQuery.
Table is uploaded to the same dataset, named {parent_table_id}_logs.
If passing status_dict, should not pass timestamp and error.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>dataset_id on BigQuery</dd>
<dt><strong><code>parent_table_id</code></strong> :&ensp;<code>str</code></dt>
<dd>table_id on BigQuery</dd>
<dt><strong><code>timestamp</code></strong> :&ensp;<code>str</code></dt>
<dd>timestamp to get datetime range</dd>
<dt><strong><code>error</code></strong> :&ensp;<code>str</code></dt>
<dd>error catched during execution</dd>
<dt><strong><code>previous_error</code></strong> :&ensp;<code>str</code></dt>
<dd>previous error catched during execution</dd>
<dt><strong><code>recapture</code></strong> :&ensp;<code>bool</code></dt>
<dd>if the execution was a recapture</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>str</code></dt>
<dd>folder to save locally, later folder which to upload to GCS</dd>
<dt><strong><code>bucket_name</code></strong> :&ensp;<code>str, Optional</code></dt>
<dd>The bucket name to save the data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<form>
<input id="lunr-search" name="q" placeholder="ðŸ”Ž Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.16.0/tingle.min.css" integrity="sha512-b+T2i3P45i1LZM7I00Ci5QquB9szqaxu+uuk5TUSGjZQ4w4n+qujQiIuvTv2BxE7WCGQCifNMksyKILDiHzsOg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.16.0/tingle.min.js" integrity="sha512-2B9/byNV1KKRm5nQ2RLViPFD6U4dUjDGwuW1GU+ImJh8YinPU9Zlq1GzdTMO+G2ROrB5o1qasJBy1ttYz0wCug==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pipelines.rj_smtr" href="index.html">pipelines.rj_smtr</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pipelines.rj_smtr.utils.bq_project" href="#pipelines.rj_smtr.utils.bq_project">bq_project</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.check_not_null" href="#pipelines.rj_smtr.utils.check_not_null">check_not_null</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.check_relation" href="#pipelines.rj_smtr.utils.check_relation">check_relation</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.close_db_connection" href="#pipelines.rj_smtr.utils.close_db_connection">close_db_connection</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.connect_ftp" href="#pipelines.rj_smtr.utils.connect_ftp">connect_ftp</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.create_bq_external_table" href="#pipelines.rj_smtr.utils.create_bq_external_table">create_bq_external_table</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.create_bq_table_schema" href="#pipelines.rj_smtr.utils.create_bq_table_schema">create_bq_table_schema</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.create_or_append_table" href="#pipelines.rj_smtr.utils.create_or_append_table">create_or_append_table</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.custom_serialization" href="#pipelines.rj_smtr.utils.custom_serialization">custom_serialization</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.data_info_str" href="#pipelines.rj_smtr.utils.data_info_str">data_info_str</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.dict_contains_keys" href="#pipelines.rj_smtr.utils.dict_contains_keys">dict_contains_keys</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.execute_db_query" href="#pipelines.rj_smtr.utils.execute_db_query">execute_db_query</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.filter_data" href="#pipelines.rj_smtr.utils.filter_data">filter_data</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.filter_null" href="#pipelines.rj_smtr.utils.filter_null">filter_null</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.format_send_discord_message" href="#pipelines.rj_smtr.utils.format_send_discord_message">format_send_discord_message</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.generate_df_and_save" href="#pipelines.rj_smtr.utils.generate_df_and_save">generate_df_and_save</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.generate_execute_schedules" href="#pipelines.rj_smtr.utils.generate_execute_schedules">generate_execute_schedules</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.get_datetime_range" href="#pipelines.rj_smtr.utils.get_datetime_range">get_datetime_range</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.get_last_run_timestamp" href="#pipelines.rj_smtr.utils.get_last_run_timestamp">get_last_run_timestamp</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.get_raw_data_api" href="#pipelines.rj_smtr.utils.get_raw_data_api">get_raw_data_api</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.get_raw_data_db" href="#pipelines.rj_smtr.utils.get_raw_data_db">get_raw_data_db</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.get_raw_data_gcs" href="#pipelines.rj_smtr.utils.get_raw_data_gcs">get_raw_data_gcs</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.get_raw_recursos" href="#pipelines.rj_smtr.utils.get_raw_recursos">get_raw_recursos</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.get_table_min_max_value" href="#pipelines.rj_smtr.utils.get_table_min_max_value">get_table_min_max_value</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.get_upload_storage_blob" href="#pipelines.rj_smtr.utils.get_upload_storage_blob">get_upload_storage_blob</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.log_critical" href="#pipelines.rj_smtr.utils.log_critical">log_critical</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.map_dict_keys" href="#pipelines.rj_smtr.utils.map_dict_keys">map_dict_keys</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.perform_check" href="#pipelines.rj_smtr.utils.perform_check">perform_check</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.perform_checks_for_table" href="#pipelines.rj_smtr.utils.perform_checks_for_table">perform_checks_for_table</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.read_raw_data" href="#pipelines.rj_smtr.utils.read_raw_data">read_raw_data</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.safe_cast" href="#pipelines.rj_smtr.utils.safe_cast">safe_cast</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.save_raw_local_func" href="#pipelines.rj_smtr.utils.save_raw_local_func">save_raw_local_func</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.save_treated_local_func" href="#pipelines.rj_smtr.utils.save_treated_local_func">save_treated_local_func</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.set_redis_rdo_files" href="#pipelines.rj_smtr.utils.set_redis_rdo_files">set_redis_rdo_files</a></code></li>
<li><code><a title="pipelines.rj_smtr.utils.upload_run_logs_to_bq" href="#pipelines.rj_smtr.utils.upload_run_logs_to_bq">upload_run_logs_to_bq</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.0</a>.</p>
</footer>
</body>
</html>
