<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pipelines.rj_cor.meteorologia.precipitacao_inea.tasks API documentation</title>
<meta name="description" content="Tasks for precipitacao_inea" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pipelines.rj_cor.meteorologia.precipitacao_inea.tasks</code></h1>
</header>
<section id="section-intro">
<p>Tasks for precipitacao_inea</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# pylint: disable=C0103
&#34;&#34;&#34;
Tasks for precipitacao_inea
&#34;&#34;&#34;
from datetime import timedelta
from pathlib import Path
from typing import Union, Tuple

import numpy as np
import pandas as pd
import pendulum
from prefect import task
from prefect.engine.signals import ENDRUN
from prefect.engine.state import Skipped, Failed
from pipelines.constants import constants
from pipelines.utils.utils import (
    log,
    parse_date_columns,
    save_updated_rows_on_redis,
    to_partitions,
)


@task(
    nout=2,
    max_retries=constants.TASK_MAX_RETRIES.value,
    retry_delay=timedelta(seconds=constants.TASK_RETRY_DELAY.value),
)
def download_data() -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Download data from API
    &#34;&#34;&#34;

    estacoes = {
        &#34;1&#34;: &#34;225543320&#34;,  # Campo Grande
        &#34;2&#34;: &#34;BE70E166&#34;,  # Capela Mayrink
        &#34;3&#34;: &#34;225543250&#34;,  # Eletrobras
        &#34;4&#34;: &#34;2243088&#34;,  # Realengo
        &#34;5&#34;: &#34;225443130&#34;,  # Sao Cristovao
    }

    dataframe = pd.DataFrame()
    for key, value in estacoes.items():
        url = f&#34;http://200.20.53.8/alertadecheias/{value}.xlsx&#34;
        dataframe_temp = pd.read_excel(url)
        dataframe_temp[&#34;id_estacao&#34;] = key
        dataframe = pd.concat([dataframe, dataframe_temp])
    return dataframe


@task(
    nout=2,
    max_retries=constants.TASK_MAX_RETRIES.value,
    retry_delay=timedelta(seconds=constants.TASK_RETRY_DELAY.value),
)
def treat_data(
    dataframe: pd.DataFrame, dataset_id: str, table_id: str, mode: str = &#34;dev&#34;
) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:
    &#34;&#34;&#34;
    Rename cols and filter data using Redis
    &#34;&#34;&#34;

    dataframe[&#34;data_medicao&#34;] = (
        pd.to_datetime(dataframe.Data, format=&#34;%d/%m/%Y&#34;).dt.strftime(&#34;%Y-%m-%d&#34;)
        + &#34; &#34;
        + dataframe[&#34;Hora&#34;]
        + &#34;:00&#34;
    )

    rename_cols = {
        &#34;Chuva Ãšltimo dado&#34;: &#34;acumulado_chuva_15_min&#34;,
        &#34; Chuva Acumulada 1H&#34;: &#34;acumulado_chuva_1_h&#34;,
        &#34; Chuva Acumulada 4H&#34;: &#34;acumulado_chuva_4_h&#34;,
        &#34; Chuva Acumulada 24H&#34;: &#34;acumulado_chuva_24_h&#34;,
        &#34; Chuva Acumulada 96H&#34;: &#34;acumulado_chuva_96_h&#34;,
        &#34; Chuva Acumulada 30D&#34;: &#34;acumulado_chuva_30_d&#34;,
        &#34; Ãšltimo NÃ­vel&#34;: &#34;altura_agua&#34;,
    }
    dataframe.rename(columns=rename_cols, inplace=True)

    # replace all &#34;Dado Nulo&#34; to nan
    dataframe.replace({&#34;Dado Nulo&#34;: np.nan}, inplace=True)

    # Eliminate where the id_estacao is the same keeping the smallest one
    dataframe.sort_values(
        [&#34;id_estacao&#34;, &#34;data_medicao&#34;] + list(rename_cols.values()), inplace=True
    )
    dataframe.drop_duplicates(subset=[&#34;id_estacao&#34;, &#34;data_medicao&#34;], keep=&#34;first&#34;)

    date_format = &#34;%Y-%m-%d %H:%M:%S&#34;
    # dataframe[&#34;data_medicao&#34;] = dataframe[&#34;data_medicao&#34;].dt.strftime(date_format)

    log(f&#34;Dataframe before comparing with last data saved on redis {dataframe.head()}&#34;)
    log(f&#34;Dataframe before comparing {dataframe[dataframe[&#39;id_estacao&#39;]==&#39;1&#39;]}&#34;)

    dataframe = save_updated_rows_on_redis(
        dataframe,
        dataset_id,
        table_id,
        unique_id=&#34;id_estacao&#34;,
        date_column=&#34;data_medicao&#34;,
        date_format=date_format,
        mode=mode,
    )

    log(f&#34;Dataframe after comparing with last data saved on redis {dataframe.head()}&#34;)
    log(f&#34;Dataframe after comparing {dataframe[dataframe[&#39;id_estacao&#39;]==&#39;1&#39;]}&#34;)

    # If df is empty stop flow
    if dataframe.shape[0] == 0:
        skip_text = &#34;No new data available on API&#34;
        log(skip_text)
        raise ENDRUN(state=Skipped(skip_text))

    pluviometric_cols = [
        &#34;id_estacao&#34;,
        &#34;data_medicao&#34;,
        &#34;acumulado_chuva_15_min&#34;,
        &#34;acumulado_chuva_1_h&#34;,
        &#34;acumulado_chuva_4_h&#34;,
        &#34;acumulado_chuva_24_h&#34;,
        &#34;acumulado_chuva_96_h&#34;,
        &#34;acumulado_chuva_30_d&#34;,
    ]
    fluviometric_cols = [&#34;id_estacao&#34;, &#34;data_medicao&#34;, &#34;altura_agua&#34;]

    dfr_pluviometric = dataframe[pluviometric_cols].copy()
    dfr_fluviometric = dataframe.loc[
        dataframe[&#34;altura_agua&#34;] != &#34;EstaÃ§Ã£o pluviomÃ©trica&#34;, fluviometric_cols
    ].copy()

    # Replace all values bigger than 10000 on &#34;altura_agua&#34; to nan
    dfr_fluviometric.loc[
        dfr_fluviometric[&#34;altura_agua&#34;] &gt; 10000, &#34;altura_agua&#34;
    ] = np.nan

    fluviometric_cols_order = [
        &#34;id_estacao&#34;,
        &#34;data_medicao&#34;,
        &#34;altura_agua&#34;,
    ]
    dfr_fluviometric = dfr_fluviometric[fluviometric_cols_order].copy()

    return dfr_pluviometric, dfr_fluviometric


@task(
    nout=2,
    max_retries=constants.TASK_MAX_RETRIES.value,
    retry_delay=timedelta(seconds=constants.TASK_RETRY_DELAY.value),
)
def check_new_data(
    dfr_pluviometric: pd.DataFrame,
    dfr_fluviometric: pd.DataFrame,
) -&gt; Tuple[bool, bool]:
    &#34;&#34;&#34;
    Check if the dataframes are empty
    &#34;&#34;&#34;

    new_pluviometric_data = True
    new_fluviometric_data = True

    if dfr_pluviometric.shape[0] == 0:
        log(&#34;No new pluviometric data available on API&#34;)
        new_pluviometric_data = False
    if dfr_fluviometric.shape[0] == 0:
        log(&#34;No new fluviometric data available on API&#34;)
        new_fluviometric_data = False
    return new_pluviometric_data, new_fluviometric_data


@task(skip_on_upstream_skip=False)
def wait_task() -&gt; None:
    &#34;&#34;&#34;Task create because prefect was messing up paths to be saved on each table&#34;&#34;&#34;
    log(&#34;End waiting pluviometric task to end.&#34;)


@task
def save_data(dataframe: pd.DataFrame, folder_name: str = None) -&gt; Union[str, Path]:
    &#34;&#34;&#34;
    Save data on a csv file to be uploaded to GCP
    &#34;&#34;&#34;

    prepath = Path(&#34;/tmp/precipitacao&#34;)
    if folder_name:
        prepath = Path(&#34;/tmp/precipitacao&#34;) / folder_name
    prepath.mkdir(parents=True, exist_ok=True)

    log(f&#34;Start saving data on {prepath}&#34;)
    log(f&#34;Data to be saved {dataframe.head()}&#34;)

    partition_column = &#34;data_medicao&#34;
    dataframe, partitions = parse_date_columns(dataframe, partition_column)
    current_time = pendulum.now(&#34;America/Sao_Paulo&#34;).strftime(&#34;%Y%m%d%H%M&#34;)

    to_partitions(
        data=dataframe,
        partition_columns=partitions,
        savepath=prepath,
        data_type=&#34;csv&#34;,
        suffix=current_time,
    )
    log(f&#34;[DEBUG] Files saved on {prepath}&#34;)
    return prepath


@task
def check_for_new_stations(
    dataframe: pd.DataFrame,
    wait=None,  # pylint: disable=unused-argument
) -&gt; None:
    &#34;&#34;&#34;
    Check if the updated stations are the same as before.
    If not, consider flow as failed and call attention to
    add this new station on estacoes_cemaden.
    I can&#39;t automatically update this new station, because
    I couldn&#39;t find a url that gives me the lat and lon for
    all the stations.
    &#34;&#34;&#34;

    stations_before = [
        &#34;1&#34;,
        &#34;2&#34;,
        &#34;3&#34;,
        &#34;4&#34;,
        &#34;5&#34;,
    ]
    new_stations = [
        i for i in dataframe.id_estacao.unique() if str(i) not in stations_before
    ]
    if len(new_stations) != 0:
        message = f&#34;New station identified. You need to update INEA\
              estacoes_inea adding station(s) {new_stations}: \
              {dataframe[dataframe.id_estacao.isin(new_stations)]}  &#34;
        log(message)
        raise ENDRUN(state=Failed(message))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.check_for_new_stations"><code class="name flex">
<span>def <span class="ident">check_for_new_stations</span></span>(<span>dataframe:Â pandas.core.frame.DataFrame, wait=None) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Check if the updated stations are the same as before.
If not, consider flow as failed and call attention to
add this new station on estacoes_cemaden.
I can't automatically update this new station, because
I couldn't find a url that gives me the lat and lon for
all the stations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def check_for_new_stations(
    dataframe: pd.DataFrame,
    wait=None,  # pylint: disable=unused-argument
) -&gt; None:
    &#34;&#34;&#34;
    Check if the updated stations are the same as before.
    If not, consider flow as failed and call attention to
    add this new station on estacoes_cemaden.
    I can&#39;t automatically update this new station, because
    I couldn&#39;t find a url that gives me the lat and lon for
    all the stations.
    &#34;&#34;&#34;

    stations_before = [
        &#34;1&#34;,
        &#34;2&#34;,
        &#34;3&#34;,
        &#34;4&#34;,
        &#34;5&#34;,
    ]
    new_stations = [
        i for i in dataframe.id_estacao.unique() if str(i) not in stations_before
    ]
    if len(new_stations) != 0:
        message = f&#34;New station identified. You need to update INEA\
              estacoes_inea adding station(s) {new_stations}: \
              {dataframe[dataframe.id_estacao.isin(new_stations)]}  &#34;
        log(message)
        raise ENDRUN(state=Failed(message))</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.check_new_data"><code class="name flex">
<span>def <span class="ident">check_new_data</span></span>(<span>dfr_pluviometric:Â pandas.core.frame.DataFrame, dfr_fluviometric:Â pandas.core.frame.DataFrame) â€‘>Â Tuple[bool,Â bool]</span>
</code></dt>
<dd>
<div class="desc"><p>Check if the dataframes are empty</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(
    nout=2,
    max_retries=constants.TASK_MAX_RETRIES.value,
    retry_delay=timedelta(seconds=constants.TASK_RETRY_DELAY.value),
)
def check_new_data(
    dfr_pluviometric: pd.DataFrame,
    dfr_fluviometric: pd.DataFrame,
) -&gt; Tuple[bool, bool]:
    &#34;&#34;&#34;
    Check if the dataframes are empty
    &#34;&#34;&#34;

    new_pluviometric_data = True
    new_fluviometric_data = True

    if dfr_pluviometric.shape[0] == 0:
        log(&#34;No new pluviometric data available on API&#34;)
        new_pluviometric_data = False
    if dfr_fluviometric.shape[0] == 0:
        log(&#34;No new fluviometric data available on API&#34;)
        new_fluviometric_data = False
    return new_pluviometric_data, new_fluviometric_data</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.download_data"><code class="name flex">
<span>def <span class="ident">download_data</span></span>(<span>) â€‘>Â pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Download data from API</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(
    nout=2,
    max_retries=constants.TASK_MAX_RETRIES.value,
    retry_delay=timedelta(seconds=constants.TASK_RETRY_DELAY.value),
)
def download_data() -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Download data from API
    &#34;&#34;&#34;

    estacoes = {
        &#34;1&#34;: &#34;225543320&#34;,  # Campo Grande
        &#34;2&#34;: &#34;BE70E166&#34;,  # Capela Mayrink
        &#34;3&#34;: &#34;225543250&#34;,  # Eletrobras
        &#34;4&#34;: &#34;2243088&#34;,  # Realengo
        &#34;5&#34;: &#34;225443130&#34;,  # Sao Cristovao
    }

    dataframe = pd.DataFrame()
    for key, value in estacoes.items():
        url = f&#34;http://200.20.53.8/alertadecheias/{value}.xlsx&#34;
        dataframe_temp = pd.read_excel(url)
        dataframe_temp[&#34;id_estacao&#34;] = key
        dataframe = pd.concat([dataframe, dataframe_temp])
    return dataframe</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.save_data"><code class="name flex">
<span>def <span class="ident">save_data</span></span>(<span>dataframe:Â pandas.core.frame.DataFrame, folder_name:Â strÂ =Â None) â€‘>Â Union[str,Â pathlib.Path]</span>
</code></dt>
<dd>
<div class="desc"><p>Save data on a csv file to be uploaded to GCP</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def save_data(dataframe: pd.DataFrame, folder_name: str = None) -&gt; Union[str, Path]:
    &#34;&#34;&#34;
    Save data on a csv file to be uploaded to GCP
    &#34;&#34;&#34;

    prepath = Path(&#34;/tmp/precipitacao&#34;)
    if folder_name:
        prepath = Path(&#34;/tmp/precipitacao&#34;) / folder_name
    prepath.mkdir(parents=True, exist_ok=True)

    log(f&#34;Start saving data on {prepath}&#34;)
    log(f&#34;Data to be saved {dataframe.head()}&#34;)

    partition_column = &#34;data_medicao&#34;
    dataframe, partitions = parse_date_columns(dataframe, partition_column)
    current_time = pendulum.now(&#34;America/Sao_Paulo&#34;).strftime(&#34;%Y%m%d%H%M&#34;)

    to_partitions(
        data=dataframe,
        partition_columns=partitions,
        savepath=prepath,
        data_type=&#34;csv&#34;,
        suffix=current_time,
    )
    log(f&#34;[DEBUG] Files saved on {prepath}&#34;)
    return prepath</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.treat_data"><code class="name flex">
<span>def <span class="ident">treat_data</span></span>(<span>dataframe:Â pandas.core.frame.DataFrame, dataset_id:Â str, table_id:Â str, mode:Â strÂ =Â 'dev') â€‘>Â Tuple[pandas.core.frame.DataFrame,Â pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Rename cols and filter data using Redis</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(
    nout=2,
    max_retries=constants.TASK_MAX_RETRIES.value,
    retry_delay=timedelta(seconds=constants.TASK_RETRY_DELAY.value),
)
def treat_data(
    dataframe: pd.DataFrame, dataset_id: str, table_id: str, mode: str = &#34;dev&#34;
) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:
    &#34;&#34;&#34;
    Rename cols and filter data using Redis
    &#34;&#34;&#34;

    dataframe[&#34;data_medicao&#34;] = (
        pd.to_datetime(dataframe.Data, format=&#34;%d/%m/%Y&#34;).dt.strftime(&#34;%Y-%m-%d&#34;)
        + &#34; &#34;
        + dataframe[&#34;Hora&#34;]
        + &#34;:00&#34;
    )

    rename_cols = {
        &#34;Chuva Ãšltimo dado&#34;: &#34;acumulado_chuva_15_min&#34;,
        &#34; Chuva Acumulada 1H&#34;: &#34;acumulado_chuva_1_h&#34;,
        &#34; Chuva Acumulada 4H&#34;: &#34;acumulado_chuva_4_h&#34;,
        &#34; Chuva Acumulada 24H&#34;: &#34;acumulado_chuva_24_h&#34;,
        &#34; Chuva Acumulada 96H&#34;: &#34;acumulado_chuva_96_h&#34;,
        &#34; Chuva Acumulada 30D&#34;: &#34;acumulado_chuva_30_d&#34;,
        &#34; Ãšltimo NÃ­vel&#34;: &#34;altura_agua&#34;,
    }
    dataframe.rename(columns=rename_cols, inplace=True)

    # replace all &#34;Dado Nulo&#34; to nan
    dataframe.replace({&#34;Dado Nulo&#34;: np.nan}, inplace=True)

    # Eliminate where the id_estacao is the same keeping the smallest one
    dataframe.sort_values(
        [&#34;id_estacao&#34;, &#34;data_medicao&#34;] + list(rename_cols.values()), inplace=True
    )
    dataframe.drop_duplicates(subset=[&#34;id_estacao&#34;, &#34;data_medicao&#34;], keep=&#34;first&#34;)

    date_format = &#34;%Y-%m-%d %H:%M:%S&#34;
    # dataframe[&#34;data_medicao&#34;] = dataframe[&#34;data_medicao&#34;].dt.strftime(date_format)

    log(f&#34;Dataframe before comparing with last data saved on redis {dataframe.head()}&#34;)
    log(f&#34;Dataframe before comparing {dataframe[dataframe[&#39;id_estacao&#39;]==&#39;1&#39;]}&#34;)

    dataframe = save_updated_rows_on_redis(
        dataframe,
        dataset_id,
        table_id,
        unique_id=&#34;id_estacao&#34;,
        date_column=&#34;data_medicao&#34;,
        date_format=date_format,
        mode=mode,
    )

    log(f&#34;Dataframe after comparing with last data saved on redis {dataframe.head()}&#34;)
    log(f&#34;Dataframe after comparing {dataframe[dataframe[&#39;id_estacao&#39;]==&#39;1&#39;]}&#34;)

    # If df is empty stop flow
    if dataframe.shape[0] == 0:
        skip_text = &#34;No new data available on API&#34;
        log(skip_text)
        raise ENDRUN(state=Skipped(skip_text))

    pluviometric_cols = [
        &#34;id_estacao&#34;,
        &#34;data_medicao&#34;,
        &#34;acumulado_chuva_15_min&#34;,
        &#34;acumulado_chuva_1_h&#34;,
        &#34;acumulado_chuva_4_h&#34;,
        &#34;acumulado_chuva_24_h&#34;,
        &#34;acumulado_chuva_96_h&#34;,
        &#34;acumulado_chuva_30_d&#34;,
    ]
    fluviometric_cols = [&#34;id_estacao&#34;, &#34;data_medicao&#34;, &#34;altura_agua&#34;]

    dfr_pluviometric = dataframe[pluviometric_cols].copy()
    dfr_fluviometric = dataframe.loc[
        dataframe[&#34;altura_agua&#34;] != &#34;EstaÃ§Ã£o pluviomÃ©trica&#34;, fluviometric_cols
    ].copy()

    # Replace all values bigger than 10000 on &#34;altura_agua&#34; to nan
    dfr_fluviometric.loc[
        dfr_fluviometric[&#34;altura_agua&#34;] &gt; 10000, &#34;altura_agua&#34;
    ] = np.nan

    fluviometric_cols_order = [
        &#34;id_estacao&#34;,
        &#34;data_medicao&#34;,
        &#34;altura_agua&#34;,
    ]
    dfr_fluviometric = dfr_fluviometric[fluviometric_cols_order].copy()

    return dfr_pluviometric, dfr_fluviometric</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.wait_task"><code class="name flex">
<span>def <span class="ident">wait_task</span></span>(<span>) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Task create because prefect was messing up paths to be saved on each table</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(skip_on_upstream_skip=False)
def wait_task() -&gt; None:
    &#34;&#34;&#34;Task create because prefect was messing up paths to be saved on each table&#34;&#34;&#34;
    log(&#34;End waiting pluviometric task to end.&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<form>
<input id="lunr-search" name="q" placeholder="ðŸ”Ž Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pipelines.rj_cor.meteorologia.precipitacao_inea" href="index.html">pipelines.rj_cor.meteorologia.precipitacao_inea</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.check_for_new_stations" href="#pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.check_for_new_stations">check_for_new_stations</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.check_new_data" href="#pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.check_new_data">check_new_data</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.download_data" href="#pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.download_data">download_data</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.save_data" href="#pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.save_data">save_data</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.treat_data" href="#pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.treat_data">treat_data</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.wait_task" href="#pipelines.rj_cor.meteorologia.precipitacao_inea.tasks.wait_task">wait_task</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>