<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pipelines.rj_cor.meteorologia.satelite.tasks API documentation</title>
<meta name="description" content="Tasks for emd" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pipelines.rj_cor.meteorologia.satelite.tasks</code></h1>
</header>
<section id="section-intro">
<p>Tasks for emd</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# pylint: disable=W0102, W0613, R0913, R0914, R0915
&#34;&#34;&#34;
Tasks for emd
&#34;&#34;&#34;

import datetime as dt
import os
import re
from pathlib import Path
from typing import Union

import pandas as pd
import pendulum
from prefect import task
from prefect.engine.signals import ENDRUN
from prefect.engine.state import Skipped

from pipelines.rj_cor.meteorologia.satelite.satellite_utils import (
    create_and_save_image,
    choose_file_to_download,
    download_blob,
    extract_julian_day_and_hour_from_filename,
    get_files_from_aws,
    get_files_from_gcp,
    get_info,
    get_variable_values,
    remap_g16,
    save_data_in_file,
)
from pipelines.utils.utils import log


@task()
def get_dates(current_time, product) -&gt; str:
    &#34;&#34;&#34;
    Task para obter o dia atual caso nenhuma data tenha sido passada
    Subtraimos 5 minutos da hora atual pois o Ãºltimo arquivo que sobre na aws
    sempre cai na hora seguinte (Exemplo: o arquivo
    OR_ABI-L2-RRQPEF-M6_G16_s20230010850208_e20230010859516_c20230010900065.nc
    cujo inÃ­cio da mediÃ§Ã£o foi Ã s 08:50 foi salvo na AWS Ã s 09:00:33).
    &#34;&#34;&#34;
    if current_time is None:
        current_time = pendulum.now(&#34;UTC&#34;).subtract(minutes=5).to_datetime_string()
    # Product sst is updating one hour later
    if product == &#34;SSTF&#34;:
        current_time = pendulum.now(&#34;UTC&#34;).subtract(minutes=55).to_datetime_string()
    return current_time


@task(nout=1)
def slice_data(current_time: str, ref_filename: str = None) -&gt; dict:
    &#34;&#34;&#34;
    slice data to separate in year, julian_day, month, day and hour in UTC
    &#34;&#34;&#34;
    if ref_filename is not None:
        year, julian_day, hour_utc = extract_julian_day_and_hour_from_filename(
            ref_filename
        )
        month = None
        day = None
    else:
        year = current_time[:4]
        month = current_time[5:7]
        day = current_time[8:10]
        hour_utc = current_time[11:13]
        julian_day = dt.datetime.strptime(current_time, &#34;%Y-%m-%d %H:%M:%S&#34;).strftime(
            &#34;%j&#34;
        )

    date_hour_info = {
        &#34;year&#34;: str(year),
        &#34;julian_day&#34;: str(julian_day),
        &#34;month&#34;: str(month),
        &#34;day&#34;: str(day),
        &#34;hour_utc&#34;: str(hour_utc),
    }

    return date_hour_info


@task(nout=2, max_retries=10, retry_delay=dt.timedelta(seconds=60))
def download(
    product: str,
    date_hour_info: dict,
    band: str = None,
    ref_filename: str = None,
    redis_files: list = [],
    wait=None,
    mode_redis: str = &#34;prod&#34;,
) -&gt; Union[str, Path]:
    &#34;&#34;&#34;
    Access S3 or GCP and download the first file on this specified date hour
    that is not already saved on redis
    &#34;&#34;&#34;

    year = date_hour_info[&#34;year&#34;]
    julian_day = date_hour_info[&#34;julian_day&#34;]
    hour_utc = date_hour_info[&#34;hour_utc&#34;][:2]
    partition_path = f&#34;ABI-L2-{product}/{year}/{julian_day}/{hour_utc}/&#34;
    log(f&#34;Getting files from {partition_path}&#34;)

    storage_files_path, storage_origin, storage_conection = get_files_from_aws(
        partition_path
    )
    log(storage_files_path)
    if len(storage_files_path) == 0:
        storage_files_path, storage_origin, storage_conection = get_files_from_gcp(
            partition_path
        )

    # Keep only files from specified band
    if product == &#34;CMIPF&#34;:
        # para capturar banda 13
        storage_files_path = [
            f for f in storage_files_path if bool(re.search(&#34;C&#34; + band, f))
        ]

    # Skip task if there is no file on API
    if len(storage_files_path) == 0:
        log(&#34;No available files on API&#34;)
        skip = Skipped(&#34;No available files on API&#34;)
        raise ENDRUN(state=skip)

    base_path = os.path.join(os.getcwd(), &#34;temp&#34;, &#34;input&#34;, mode_redis, product[:-1])

    if not os.path.exists(base_path):
        os.makedirs(base_path)

    # Seleciona primeiro arquivo que nÃ£o tem o nome salvo no redis
    log(f&#34;\n\n[DEBUG]: available files on API: {storage_files_path}&#34;)
    log(f&#34;\n\n[DEBUG]: filenames that are already saved on redis_files: {redis_files}&#34;)

    redis_files, destination_file_path, download_file = choose_file_to_download(
        storage_files_path, base_path, redis_files, ref_filename
    )

    # Skip task if there is no new file
    if download_file is None:
        log(&#34;No new available files&#34;)
        skip = Skipped(&#34;No new available files&#34;)
        raise ENDRUN(state=skip)

    # Download file from aws or gcp
    if storage_origin == &#34;aws&#34;:
        storage_conection.get(download_file, destination_file_path)
    else:
        download_blob(
            bucket_name=storage_conection,
            source_blob_name=download_file,
            destination_file_name=destination_file_path,
            mode=&#34;prod&#34;,
        )

    return destination_file_path, redis_files


@task
def tratar_dados(filename: str) -&gt; dict:
    &#34;&#34;&#34;
    Convert X, Y coordinates from netcdf file to a latlon coordinates
    and select only the specified region on extent variable.
    &#34;&#34;&#34;
    log(f&#34;\n Started treating file: {filename}&#34;)
    # Create the basemap reference for the Rectangular Projection.
    # You may choose the region you want.

    # Full Disk Extent
    # extent = [-156.00, -81.30, 6.30, 81.30]

    # Brazil region
    # extent = [-90.0, -40.0, -20.0, 10.0]

    # Estado do RJ
    # lat_max, lon_max = (-20.69080839963545, -40.28483671464648)
    # lat_min, lon_min = (-23.801876626302175, -45.05290312102409)

    # RegiÃ£o da cidade do Rio de Janeiro
    # lat_max, lon_min = (-22.802842397418548, -43.81200531887697)
    # lat_min, lon_max = (-23.073487725280266, -43.11300020870994)

    # Recorte da regiÃ£o da cidade do Rio de Janeiro segundo meteorologista
    lat_max, lon_max = (
        -21.699774257353113,
        -42.35676996062447,
    )  # canto superior direito
    lat_min, lon_min = (
        -23.801876626302175,
        -45.05290312102409,
    )  # canto inferior esquerdo

    extent = [lon_min, lat_min, lon_max, lat_max]

    # Get informations from the nc file
    product_caracteristics = get_info(filename)
    product_caracteristics[&#34;extent&#34;] = extent

    # Call the remap function to convert x, y to lon, lat and save converted file
    remap_g16(
        filename,
        extent,
        product=product_caracteristics[&#34;product&#34;],
        variable=product_caracteristics[&#34;variable&#34;],
    )

    return product_caracteristics


@task(nout=2)
def save_data(info: dict, mode_redis: str = &#34;prod&#34;) -&gt; Union[str, Path]:
    &#34;&#34;&#34;
    Concat all netcdf data and save partitioned by date on a csv
    &#34;&#34;&#34;

    log(&#34;Start saving product on a csv&#34;)
    output_path, output_filepath = save_data_in_file(
        product=info[&#34;product&#34;],
        variable=info[&#34;variable&#34;],
        datetime_save=info[&#34;datetime_save&#34;],
        mode_redis=mode_redis,
    )
    return output_path, output_filepath


@task
def create_image_and_upload_to_api(info: dict, output_filepath: Path):
    &#34;&#34;&#34;
    Create image from dataframe and send it to API
    &#34;&#34;&#34;

    dfr = pd.read_csv(output_filepath)

    dfr = dfr.sort_values(by=[&#34;latitude&#34;, &#34;longitude&#34;], ascending=[False, True])

    for var in info[&#34;variable&#34;]:
        log(f&#34;\nStart creating image for variable {var}\n&#34;)

        var = var.lower()
        data_array = get_variable_values(dfr, var)

        # Get the pixel values
        data = data_array.data[:]
        log(f&#34;\n[DEBUG] data {data}&#34;)
        save_image_path = create_and_save_image(data, info, var)
        log(f&#34;\nStart uploading image for variable {var} on API\n&#34;)
        # upload_image_to_api(info, save_image_path)
        log(save_image_path)
        log(f&#34;\nEnd uploading image for variable {var} on API\n&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pipelines.rj_cor.meteorologia.satelite.tasks.create_image_and_upload_to_api"><code class="name flex">
<span>def <span class="ident">create_image_and_upload_to_api</span></span>(<span>info:Â dict, output_filepath:Â pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Create image from dataframe and send it to API</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def create_image_and_upload_to_api(info: dict, output_filepath: Path):
    &#34;&#34;&#34;
    Create image from dataframe and send it to API
    &#34;&#34;&#34;

    dfr = pd.read_csv(output_filepath)

    dfr = dfr.sort_values(by=[&#34;latitude&#34;, &#34;longitude&#34;], ascending=[False, True])

    for var in info[&#34;variable&#34;]:
        log(f&#34;\nStart creating image for variable {var}\n&#34;)

        var = var.lower()
        data_array = get_variable_values(dfr, var)

        # Get the pixel values
        data = data_array.data[:]
        log(f&#34;\n[DEBUG] data {data}&#34;)
        save_image_path = create_and_save_image(data, info, var)
        log(f&#34;\nStart uploading image for variable {var} on API\n&#34;)
        # upload_image_to_api(info, save_image_path)
        log(save_image_path)
        log(f&#34;\nEnd uploading image for variable {var} on API\n&#34;)</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.satelite.tasks.download"><code class="name flex">
<span>def <span class="ident">download</span></span>(<span>product:Â str, date_hour_info:Â dict, band:Â strÂ =Â None, ref_filename:Â strÂ =Â None, redis_files:Â listÂ =Â [], wait=None, mode_redis:Â strÂ =Â 'prod') â€‘>Â Union[str,Â pathlib.Path]</span>
</code></dt>
<dd>
<div class="desc"><p>Access S3 or GCP and download the first file on this specified date hour
that is not already saved on redis</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(nout=2, max_retries=10, retry_delay=dt.timedelta(seconds=60))
def download(
    product: str,
    date_hour_info: dict,
    band: str = None,
    ref_filename: str = None,
    redis_files: list = [],
    wait=None,
    mode_redis: str = &#34;prod&#34;,
) -&gt; Union[str, Path]:
    &#34;&#34;&#34;
    Access S3 or GCP and download the first file on this specified date hour
    that is not already saved on redis
    &#34;&#34;&#34;

    year = date_hour_info[&#34;year&#34;]
    julian_day = date_hour_info[&#34;julian_day&#34;]
    hour_utc = date_hour_info[&#34;hour_utc&#34;][:2]
    partition_path = f&#34;ABI-L2-{product}/{year}/{julian_day}/{hour_utc}/&#34;
    log(f&#34;Getting files from {partition_path}&#34;)

    storage_files_path, storage_origin, storage_conection = get_files_from_aws(
        partition_path
    )
    log(storage_files_path)
    if len(storage_files_path) == 0:
        storage_files_path, storage_origin, storage_conection = get_files_from_gcp(
            partition_path
        )

    # Keep only files from specified band
    if product == &#34;CMIPF&#34;:
        # para capturar banda 13
        storage_files_path = [
            f for f in storage_files_path if bool(re.search(&#34;C&#34; + band, f))
        ]

    # Skip task if there is no file on API
    if len(storage_files_path) == 0:
        log(&#34;No available files on API&#34;)
        skip = Skipped(&#34;No available files on API&#34;)
        raise ENDRUN(state=skip)

    base_path = os.path.join(os.getcwd(), &#34;temp&#34;, &#34;input&#34;, mode_redis, product[:-1])

    if not os.path.exists(base_path):
        os.makedirs(base_path)

    # Seleciona primeiro arquivo que nÃ£o tem o nome salvo no redis
    log(f&#34;\n\n[DEBUG]: available files on API: {storage_files_path}&#34;)
    log(f&#34;\n\n[DEBUG]: filenames that are already saved on redis_files: {redis_files}&#34;)

    redis_files, destination_file_path, download_file = choose_file_to_download(
        storage_files_path, base_path, redis_files, ref_filename
    )

    # Skip task if there is no new file
    if download_file is None:
        log(&#34;No new available files&#34;)
        skip = Skipped(&#34;No new available files&#34;)
        raise ENDRUN(state=skip)

    # Download file from aws or gcp
    if storage_origin == &#34;aws&#34;:
        storage_conection.get(download_file, destination_file_path)
    else:
        download_blob(
            bucket_name=storage_conection,
            source_blob_name=download_file,
            destination_file_name=destination_file_path,
            mode=&#34;prod&#34;,
        )

    return destination_file_path, redis_files</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.satelite.tasks.get_dates"><code class="name flex">
<span>def <span class="ident">get_dates</span></span>(<span>current_time, product) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Task para obter o dia atual caso nenhuma data tenha sido passada
Subtraimos 5 minutos da hora atual pois o Ãºltimo arquivo que sobre na aws
sempre cai na hora seguinte (Exemplo: o arquivo
OR_ABI-L2-RRQPEF-M6_G16_s20230010850208_e20230010859516_c20230010900065.nc
cujo inÃ­cio da mediÃ§Ã£o foi Ã s 08:50 foi salvo na AWS Ã s 09:00:33).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task()
def get_dates(current_time, product) -&gt; str:
    &#34;&#34;&#34;
    Task para obter o dia atual caso nenhuma data tenha sido passada
    Subtraimos 5 minutos da hora atual pois o Ãºltimo arquivo que sobre na aws
    sempre cai na hora seguinte (Exemplo: o arquivo
    OR_ABI-L2-RRQPEF-M6_G16_s20230010850208_e20230010859516_c20230010900065.nc
    cujo inÃ­cio da mediÃ§Ã£o foi Ã s 08:50 foi salvo na AWS Ã s 09:00:33).
    &#34;&#34;&#34;
    if current_time is None:
        current_time = pendulum.now(&#34;UTC&#34;).subtract(minutes=5).to_datetime_string()
    # Product sst is updating one hour later
    if product == &#34;SSTF&#34;:
        current_time = pendulum.now(&#34;UTC&#34;).subtract(minutes=55).to_datetime_string()
    return current_time</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.satelite.tasks.save_data"><code class="name flex">
<span>def <span class="ident">save_data</span></span>(<span>info:Â dict, mode_redis:Â strÂ =Â 'prod') â€‘>Â Union[str,Â pathlib.Path]</span>
</code></dt>
<dd>
<div class="desc"><p>Concat all netcdf data and save partitioned by date on a csv</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(nout=2)
def save_data(info: dict, mode_redis: str = &#34;prod&#34;) -&gt; Union[str, Path]:
    &#34;&#34;&#34;
    Concat all netcdf data and save partitioned by date on a csv
    &#34;&#34;&#34;

    log(&#34;Start saving product on a csv&#34;)
    output_path, output_filepath = save_data_in_file(
        product=info[&#34;product&#34;],
        variable=info[&#34;variable&#34;],
        datetime_save=info[&#34;datetime_save&#34;],
        mode_redis=mode_redis,
    )
    return output_path, output_filepath</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.satelite.tasks.slice_data"><code class="name flex">
<span>def <span class="ident">slice_data</span></span>(<span>current_time:Â str, ref_filename:Â strÂ =Â None) â€‘>Â dict</span>
</code></dt>
<dd>
<div class="desc"><p>slice data to separate in year, julian_day, month, day and hour in UTC</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(nout=1)
def slice_data(current_time: str, ref_filename: str = None) -&gt; dict:
    &#34;&#34;&#34;
    slice data to separate in year, julian_day, month, day and hour in UTC
    &#34;&#34;&#34;
    if ref_filename is not None:
        year, julian_day, hour_utc = extract_julian_day_and_hour_from_filename(
            ref_filename
        )
        month = None
        day = None
    else:
        year = current_time[:4]
        month = current_time[5:7]
        day = current_time[8:10]
        hour_utc = current_time[11:13]
        julian_day = dt.datetime.strptime(current_time, &#34;%Y-%m-%d %H:%M:%S&#34;).strftime(
            &#34;%j&#34;
        )

    date_hour_info = {
        &#34;year&#34;: str(year),
        &#34;julian_day&#34;: str(julian_day),
        &#34;month&#34;: str(month),
        &#34;day&#34;: str(day),
        &#34;hour_utc&#34;: str(hour_utc),
    }

    return date_hour_info</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.satelite.tasks.tratar_dados"><code class="name flex">
<span>def <span class="ident">tratar_dados</span></span>(<span>filename:Â str) â€‘>Â dict</span>
</code></dt>
<dd>
<div class="desc"><p>Convert X, Y coordinates from netcdf file to a latlon coordinates
and select only the specified region on extent variable.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def tratar_dados(filename: str) -&gt; dict:
    &#34;&#34;&#34;
    Convert X, Y coordinates from netcdf file to a latlon coordinates
    and select only the specified region on extent variable.
    &#34;&#34;&#34;
    log(f&#34;\n Started treating file: {filename}&#34;)
    # Create the basemap reference for the Rectangular Projection.
    # You may choose the region you want.

    # Full Disk Extent
    # extent = [-156.00, -81.30, 6.30, 81.30]

    # Brazil region
    # extent = [-90.0, -40.0, -20.0, 10.0]

    # Estado do RJ
    # lat_max, lon_max = (-20.69080839963545, -40.28483671464648)
    # lat_min, lon_min = (-23.801876626302175, -45.05290312102409)

    # RegiÃ£o da cidade do Rio de Janeiro
    # lat_max, lon_min = (-22.802842397418548, -43.81200531887697)
    # lat_min, lon_max = (-23.073487725280266, -43.11300020870994)

    # Recorte da regiÃ£o da cidade do Rio de Janeiro segundo meteorologista
    lat_max, lon_max = (
        -21.699774257353113,
        -42.35676996062447,
    )  # canto superior direito
    lat_min, lon_min = (
        -23.801876626302175,
        -45.05290312102409,
    )  # canto inferior esquerdo

    extent = [lon_min, lat_min, lon_max, lat_max]

    # Get informations from the nc file
    product_caracteristics = get_info(filename)
    product_caracteristics[&#34;extent&#34;] = extent

    # Call the remap function to convert x, y to lon, lat and save converted file
    remap_g16(
        filename,
        extent,
        product=product_caracteristics[&#34;product&#34;],
        variable=product_caracteristics[&#34;variable&#34;],
    )

    return product_caracteristics</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<form>
<input id="lunr-search" name="q" placeholder="ðŸ”Ž Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pipelines.rj_cor.meteorologia.satelite" href="index.html">pipelines.rj_cor.meteorologia.satelite</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pipelines.rj_cor.meteorologia.satelite.tasks.create_image_and_upload_to_api" href="#pipelines.rj_cor.meteorologia.satelite.tasks.create_image_and_upload_to_api">create_image_and_upload_to_api</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.satelite.tasks.download" href="#pipelines.rj_cor.meteorologia.satelite.tasks.download">download</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.satelite.tasks.get_dates" href="#pipelines.rj_cor.meteorologia.satelite.tasks.get_dates">get_dates</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.satelite.tasks.save_data" href="#pipelines.rj_cor.meteorologia.satelite.tasks.save_data">save_data</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.satelite.tasks.slice_data" href="#pipelines.rj_cor.meteorologia.satelite.tasks.slice_data">slice_data</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.satelite.tasks.tratar_dados" href="#pipelines.rj_cor.meteorologia.satelite.tasks.tratar_dados">tratar_dados</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>