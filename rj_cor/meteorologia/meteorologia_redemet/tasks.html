<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks API documentation</title>
<meta name="description" content="Tasks for meteorologia_redemet" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks</code></h1>
</header>
<section id="section-intro">
<p>Tasks for meteorologia_redemet</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Tasks for meteorologia_redemet
&#34;&#34;&#34;
from datetime import timedelta
import json
from pathlib import Path
from typing import Tuple, Union

import pandas as pd
import pendulum
from prefect import task
import requests

from pipelines.constants import constants
from pipelines.utils.utils import (
    get_vault_secret,
    log,
    to_partitions,
    parse_date_columns,
)


@task(nout=3)
def get_dates(data_inicio: str, data_fim: str) -&gt; Tuple[str, str]:
    &#34;&#34;&#34;
    Task para obter o dia de início e o de fim.
    Se nenhuma data foi passada a data_inicio corresponde a ontem
    e data_fim a hoje e não estamos fazendo backfill.
    Caso contrário, retorna as datas inputadas mos parâmetros do flow.
    &#34;&#34;&#34;
    # a API sempre retorna o dado em UTC
    log(f&#34;data de inicio e fim antes do if {data_inicio} {data_fim}&#34;)
    if data_inicio == &#34;&#34;:
        data_fim = pendulum.now(&#34;UTC&#34;).format(&#34;YYYY-MM-DD&#34;)
        data_inicio = pendulum.yesterday(&#34;UTC&#34;).format(&#34;YYYY-MM-DD&#34;)
        backfill = 0
    else:
        backfill = 1
    log(f&#34;data de inicio e fim dps do if {data_inicio} {data_fim}&#34;)

    return data_inicio, data_fim, backfill


@task(
    max_retries=constants.TASK_MAX_RETRIES.value,
    retry_delay=timedelta(seconds=constants.TASK_RETRY_DELAY.value),
)
def download(data_inicio: str, data_fim: str) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Faz o request na data especificada e retorna dados
    &#34;&#34;&#34;

    # Lista com as estações da cidade do Rio de Janeiro
    estacoes_unicas = [
        &#34;SBAF&#34;,
        &#34;SBGL&#34;,
        &#34;SBJR&#34;,
        &#34;SBRJ&#34;,
        &#34;SBSC&#34;,
    ]

    dicionario = get_vault_secret(&#34;redemet-token&#34;)

    # Converte datas em int para cálculo de faixas.
    data_inicio_int = int(data_inicio.replace(&#34;-&#34;, &#34;&#34;))
    data_fim_int = int(data_fim.replace(&#34;-&#34;, &#34;&#34;))

    raw = []
    for id_estacao in estacoes_unicas:
        base_url = f&#34;https://api-redemet.decea.mil.br/aerodromos/info?api_key={dicionario[&#39;data&#39;][&#39;token&#39;]}&#34;  # noqa
        for data in range(data_inicio_int, data_fim_int + 1):
            for hora in range(24):
                url = f&#34;{base_url}&amp;localidade={id_estacao}&amp;datahora={data:06}{hora:02}&#34;
                res = requests.get(url)
                if res.status_code != 200:
                    log(f&#34;Problema no id: {id_estacao}, {res.status_code}, {url}&#34;)
                    continue
                res_data = json.loads(res.text)
                if res_data[&#34;status&#34;] is not True:
                    log(f&#34;Problema no id: {id_estacao}, {res_data[&#39;message&#39;]}, {url}&#34;)
                    continue
                if &#34;data&#34; not in res_data[&#34;data&#34;]:
                    # Sem dados para esse horario
                    continue
                raw.append(res_data)

    # Extrai objetos de dados
    raw = [res_data[&#34;data&#34;] for res_data in raw]

    # converte para dados
    dados = pd.DataFrame(raw)

    return dados


@task
def tratar_dados(dados: pd.DataFrame, backfill: bool = 0) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Renomeia colunas e filtra dados com a hora do timestamp de execução
    &#34;&#34;&#34;

    drop_cols = [&#34;nome&#34;, &#34;cidade&#34;, &#34;lon&#34;, &#34;lat&#34;, &#34;localizacao&#34;, &#34;tempoImagem&#34;, &#34;metar&#34;]
    # Checa se todas estão no df
    drop_cols = [c for c in drop_cols if c in dados.columns]

    # Remove colunas que já temos os dados em outras tabelas
    dados = dados.drop(drop_cols, axis=1)

    # Adequando nome das variáveis
    rename_cols = {
        &#34;localidade&#34;: &#34;id_estacao&#34;,
        &#34;ur&#34;: &#34;umidade&#34;,
    }

    dados = dados.rename(columns=rename_cols)

    # Converte horário de UTC para America/Sao Paulo
    formato = &#34;DD/MM/YYYY HH:mm(z)&#34;
    dados[&#34;data&#34;] = dados[&#34;data&#34;].apply(
        lambda x: pendulum.from_format(x, formato)
        .in_tz(&#34;America/Sao_Paulo&#34;)
        .format(formato)
    )

    # Ordenamento de variáveis
    chaves_primarias = [&#34;id_estacao&#34;, &#34;data&#34;]
    demais_cols = [c for c in dados.columns if c not in chaves_primarias]

    dados = dados[chaves_primarias + demais_cols]

    # Converte variáveis que deveriam ser int para int
    dados[&#34;temperatura&#34;] = dados[&#34;temperatura&#34;].apply(
        lambda x: None if x[:-2] == &#34;NIL&#34; else int(x[:-2])
    )
    dados[&#34;umidade&#34;] = dados[&#34;umidade&#34;].apply(
        lambda x: None if &#34;%&#34; not in x else int(x[:-1])
    )

    dados[&#34;data&#34;] = pd.to_datetime(dados.data, format=&#34;%d/%m/%Y %H:%M(%Z)&#34;)

    # Pegar o dia no nosso timezone como partição
    br_timezone = pendulum.now(&#34;America/Sao_Paulo&#34;).format(&#34;YYYY-MM-DD&#34;)

    # Define colunas que serão salvas
    dados = dados[
        [
            &#34;id_estacao&#34;,
            &#34;data&#34;,
            &#34;temperatura&#34;,
            &#34;umidade&#34;,
            &#34;condicoes_tempo&#34;,
            &#34;ceu&#34;,
            &#34;teto&#34;,
            &#34;visibilidade&#34;,
        ]
    ]

    # Remover dados duplicados
    dados = dados.drop_duplicates(subset=[&#34;id_estacao&#34;, &#34;data&#34;])

    log(f&#34;Dados antes do filtro dia:\n{dados[[&#39;id_estacao&#39;, &#39;data&#39;]]}&#34;)

    if not backfill:
        # Seleciona apenas dados daquele dia (devido à UTC)
        dados = dados[dados[&#34;data&#34;].dt.date.astype(str) == br_timezone]

    log(f&#34;&gt;&gt;&gt;&gt; min hora {dados[~dados.temperatura.isna()].data.min()}&#34;)
    log(f&#34;&gt;&gt;&gt;&gt; max hora {dados[~dados.temperatura.isna()].data.max()}&#34;)

    # Remover fuso horário
    dados[&#34;data&#34;] = dados[&#34;data&#34;].dt.strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)
    dados.rename(columns={&#34;data&#34;: &#34;data_medicao&#34;}, inplace=True)

    # Capitalizar os dados da coluna céu
    dados[&#34;ceu&#34;] = dados[&#34;ceu&#34;].str.capitalize()

    return dados


@task
def salvar_dados(dados: pd.DataFrame) -&gt; Union[str, Path]:
    &#34;&#34;&#34;
    Salvar dados em csv
    &#34;&#34;&#34;

    prepath = Path(&#34;/tmp/meteorologia_redemet/&#34;)
    prepath.mkdir(parents=True, exist_ok=True)

    partition_column = &#34;data_medicao&#34;
    dataframe, partitions = parse_date_columns(dados, partition_column)

    # Cria partições a partir da data
    to_partitions(
        data=dataframe,
        partition_columns=partitions,
        savepath=prepath,
        data_type=&#34;csv&#34;,
    )
    log(f&#34;[DEBUG] Files saved on {prepath}&#34;)
    return prepath</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.download"><code class="name flex">
<span>def <span class="ident">download</span></span>(<span>data_inicio: str, data_fim: str) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Faz o request na data especificada e retorna dados</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(
    max_retries=constants.TASK_MAX_RETRIES.value,
    retry_delay=timedelta(seconds=constants.TASK_RETRY_DELAY.value),
)
def download(data_inicio: str, data_fim: str) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Faz o request na data especificada e retorna dados
    &#34;&#34;&#34;

    # Lista com as estações da cidade do Rio de Janeiro
    estacoes_unicas = [
        &#34;SBAF&#34;,
        &#34;SBGL&#34;,
        &#34;SBJR&#34;,
        &#34;SBRJ&#34;,
        &#34;SBSC&#34;,
    ]

    dicionario = get_vault_secret(&#34;redemet-token&#34;)

    # Converte datas em int para cálculo de faixas.
    data_inicio_int = int(data_inicio.replace(&#34;-&#34;, &#34;&#34;))
    data_fim_int = int(data_fim.replace(&#34;-&#34;, &#34;&#34;))

    raw = []
    for id_estacao in estacoes_unicas:
        base_url = f&#34;https://api-redemet.decea.mil.br/aerodromos/info?api_key={dicionario[&#39;data&#39;][&#39;token&#39;]}&#34;  # noqa
        for data in range(data_inicio_int, data_fim_int + 1):
            for hora in range(24):
                url = f&#34;{base_url}&amp;localidade={id_estacao}&amp;datahora={data:06}{hora:02}&#34;
                res = requests.get(url)
                if res.status_code != 200:
                    log(f&#34;Problema no id: {id_estacao}, {res.status_code}, {url}&#34;)
                    continue
                res_data = json.loads(res.text)
                if res_data[&#34;status&#34;] is not True:
                    log(f&#34;Problema no id: {id_estacao}, {res_data[&#39;message&#39;]}, {url}&#34;)
                    continue
                if &#34;data&#34; not in res_data[&#34;data&#34;]:
                    # Sem dados para esse horario
                    continue
                raw.append(res_data)

    # Extrai objetos de dados
    raw = [res_data[&#34;data&#34;] for res_data in raw]

    # converte para dados
    dados = pd.DataFrame(raw)

    return dados</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.get_dates"><code class="name flex">
<span>def <span class="ident">get_dates</span></span>(<span>data_inicio: str, data_fim: str) ‑> Tuple[str, str]</span>
</code></dt>
<dd>
<div class="desc"><p>Task para obter o dia de início e o de fim.
Se nenhuma data foi passada a data_inicio corresponde a ontem
e data_fim a hoje e não estamos fazendo backfill.
Caso contrário, retorna as datas inputadas mos parâmetros do flow.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task(nout=3)
def get_dates(data_inicio: str, data_fim: str) -&gt; Tuple[str, str]:
    &#34;&#34;&#34;
    Task para obter o dia de início e o de fim.
    Se nenhuma data foi passada a data_inicio corresponde a ontem
    e data_fim a hoje e não estamos fazendo backfill.
    Caso contrário, retorna as datas inputadas mos parâmetros do flow.
    &#34;&#34;&#34;
    # a API sempre retorna o dado em UTC
    log(f&#34;data de inicio e fim antes do if {data_inicio} {data_fim}&#34;)
    if data_inicio == &#34;&#34;:
        data_fim = pendulum.now(&#34;UTC&#34;).format(&#34;YYYY-MM-DD&#34;)
        data_inicio = pendulum.yesterday(&#34;UTC&#34;).format(&#34;YYYY-MM-DD&#34;)
        backfill = 0
    else:
        backfill = 1
    log(f&#34;data de inicio e fim dps do if {data_inicio} {data_fim}&#34;)

    return data_inicio, data_fim, backfill</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.salvar_dados"><code class="name flex">
<span>def <span class="ident">salvar_dados</span></span>(<span>dados: pandas.core.frame.DataFrame) ‑> Union[str, pathlib.Path]</span>
</code></dt>
<dd>
<div class="desc"><p>Salvar dados em csv</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def salvar_dados(dados: pd.DataFrame) -&gt; Union[str, Path]:
    &#34;&#34;&#34;
    Salvar dados em csv
    &#34;&#34;&#34;

    prepath = Path(&#34;/tmp/meteorologia_redemet/&#34;)
    prepath.mkdir(parents=True, exist_ok=True)

    partition_column = &#34;data_medicao&#34;
    dataframe, partitions = parse_date_columns(dados, partition_column)

    # Cria partições a partir da data
    to_partitions(
        data=dataframe,
        partition_columns=partitions,
        savepath=prepath,
        data_type=&#34;csv&#34;,
    )
    log(f&#34;[DEBUG] Files saved on {prepath}&#34;)
    return prepath</code></pre>
</details>
</dd>
<dt id="pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.tratar_dados"><code class="name flex">
<span>def <span class="ident">tratar_dados</span></span>(<span>dados: pandas.core.frame.DataFrame, backfill: bool = 0) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Renomeia colunas e filtra dados com a hora do timestamp de execução</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@task
def tratar_dados(dados: pd.DataFrame, backfill: bool = 0) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Renomeia colunas e filtra dados com a hora do timestamp de execução
    &#34;&#34;&#34;

    drop_cols = [&#34;nome&#34;, &#34;cidade&#34;, &#34;lon&#34;, &#34;lat&#34;, &#34;localizacao&#34;, &#34;tempoImagem&#34;, &#34;metar&#34;]
    # Checa se todas estão no df
    drop_cols = [c for c in drop_cols if c in dados.columns]

    # Remove colunas que já temos os dados em outras tabelas
    dados = dados.drop(drop_cols, axis=1)

    # Adequando nome das variáveis
    rename_cols = {
        &#34;localidade&#34;: &#34;id_estacao&#34;,
        &#34;ur&#34;: &#34;umidade&#34;,
    }

    dados = dados.rename(columns=rename_cols)

    # Converte horário de UTC para America/Sao Paulo
    formato = &#34;DD/MM/YYYY HH:mm(z)&#34;
    dados[&#34;data&#34;] = dados[&#34;data&#34;].apply(
        lambda x: pendulum.from_format(x, formato)
        .in_tz(&#34;America/Sao_Paulo&#34;)
        .format(formato)
    )

    # Ordenamento de variáveis
    chaves_primarias = [&#34;id_estacao&#34;, &#34;data&#34;]
    demais_cols = [c for c in dados.columns if c not in chaves_primarias]

    dados = dados[chaves_primarias + demais_cols]

    # Converte variáveis que deveriam ser int para int
    dados[&#34;temperatura&#34;] = dados[&#34;temperatura&#34;].apply(
        lambda x: None if x[:-2] == &#34;NIL&#34; else int(x[:-2])
    )
    dados[&#34;umidade&#34;] = dados[&#34;umidade&#34;].apply(
        lambda x: None if &#34;%&#34; not in x else int(x[:-1])
    )

    dados[&#34;data&#34;] = pd.to_datetime(dados.data, format=&#34;%d/%m/%Y %H:%M(%Z)&#34;)

    # Pegar o dia no nosso timezone como partição
    br_timezone = pendulum.now(&#34;America/Sao_Paulo&#34;).format(&#34;YYYY-MM-DD&#34;)

    # Define colunas que serão salvas
    dados = dados[
        [
            &#34;id_estacao&#34;,
            &#34;data&#34;,
            &#34;temperatura&#34;,
            &#34;umidade&#34;,
            &#34;condicoes_tempo&#34;,
            &#34;ceu&#34;,
            &#34;teto&#34;,
            &#34;visibilidade&#34;,
        ]
    ]

    # Remover dados duplicados
    dados = dados.drop_duplicates(subset=[&#34;id_estacao&#34;, &#34;data&#34;])

    log(f&#34;Dados antes do filtro dia:\n{dados[[&#39;id_estacao&#39;, &#39;data&#39;]]}&#34;)

    if not backfill:
        # Seleciona apenas dados daquele dia (devido à UTC)
        dados = dados[dados[&#34;data&#34;].dt.date.astype(str) == br_timezone]

    log(f&#34;&gt;&gt;&gt;&gt; min hora {dados[~dados.temperatura.isna()].data.min()}&#34;)
    log(f&#34;&gt;&gt;&gt;&gt; max hora {dados[~dados.temperatura.isna()].data.max()}&#34;)

    # Remover fuso horário
    dados[&#34;data&#34;] = dados[&#34;data&#34;].dt.strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)
    dados.rename(columns={&#34;data&#34;: &#34;data_medicao&#34;}, inplace=True)

    # Capitalizar os dados da coluna céu
    dados[&#34;ceu&#34;] = dados[&#34;ceu&#34;].str.capitalize()

    return dados</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<form>
<input id="lunr-search" name="q" placeholder="🔎 Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pipelines.rj_cor.meteorologia.meteorologia_redemet" href="index.html">pipelines.rj_cor.meteorologia.meteorologia_redemet</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.download" href="#pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.download">download</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.get_dates" href="#pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.get_dates">get_dates</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.salvar_dados" href="#pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.salvar_dados">salvar_dados</a></code></li>
<li><code><a title="pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.tratar_dados" href="#pipelines.rj_cor.meteorologia.meteorologia_redemet.tasks.tratar_dados">tratar_dados</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>